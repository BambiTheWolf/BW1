{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a6b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ed43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.yelp.co.uk/search?find_desc=Hotels&find_loc=amsterdam\")\n",
    "\n",
    "time.sleep(np.random.uniform(5,10))\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca8105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_href = soup.find_all(\"a\", class_=\"css-166la90\", href=True)\n",
    "pageLinks = []\n",
    "listLinks = []\n",
    "pageStarts = [\"90\", \"100\", \"110\", \"120\" , \"130\", \"140\", \"150\", \"160\", \"170\", \"180\", \"190\", \"200\", \"210\", \"220\", \"230\"]\n",
    "\n",
    "\n",
    "for link in page_href[0 : 10]: \n",
    "    pageLinks.append(\"https://www.yelp.co.uk\" + link[\"href\"])\n",
    "    \n",
    "for link in page_href[10:18]:\n",
    "    listLinks.append(link[\"href\"])\n",
    "    \n",
    "for num in pageStarts:\n",
    "    listLinks.append(f\"https://www.yelp.co.uk/search?find_desc=Hotels&find_loc=amsterdam&start={num}\")\n",
    "\n",
    "\n",
    "for link in listLinks:\n",
    "    page1 = requests.get(link)\n",
    "    \n",
    "    time.sleep(np.random.uniform(5,10))\n",
    "    \n",
    "    soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "    \n",
    "    page1_href = soup1.find_all(\"a\", class_=\"css-166la90\", href=True)\n",
    "    \n",
    "    for link in page1_href[0 : 10]: \n",
    "        pageLinks.append(\"https://www.yelp.co.uk\" + link[\"href\"])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d64dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = pd.DataFrame(listLinks)\n",
    "dfHotels = pd.DataFrame(pageLinks)\n",
    "\n",
    "dfList.to_csv(\"Hotel List Links.csv\")\n",
    "dfHotels.to_csv(\"Hotel Pages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c70134b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotelNames = []\n",
    "ratings = []\n",
    "numberOfReviews= []\n",
    "priceRange = []\n",
    "numberOfPhotos = []\n",
    "location = []\n",
    "street = []\n",
    "classification = []\n",
    "amenities = []\n",
    "amenity = []\n",
    "\n",
    "for link in pageLinks[:50]:\n",
    "    \n",
    "    \n",
    "    page2 = requests.get(link)\n",
    "    \n",
    "    \n",
    "    soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "    \n",
    "    bN= soup2.find(\"h1\", class_=\"css-11q1g5y\")\n",
    "    if bN == None:\n",
    "        hotelNames.append([])\n",
    "    else:\n",
    "        hotelNames.append(bN.text)\n",
    "\n",
    "#     rate = soup2.find(\"span\", class_=\"display--inline__373c0__2SfH_ border-color--default__373c0__30oMI\")\n",
    "#     if rate == None:\n",
    "#         ratings.append([])\n",
    "#     elif ratings == 1:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate))\n",
    "#     else:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate)[0])\n",
    "\n",
    "    nR = soup2.find(\"span\", class_=\"css-bq71j2\")\n",
    "    if nR == None:\n",
    "        numberOfReviews.append([])\n",
    "    else:\n",
    "        numberOfReviews.append(nR.text.split()[0])\n",
    "\n",
    "    pricing = soup2.find_all(\"span\", class_=\"css-1xxismk\")\n",
    "    if len(pricing) == 0 or pricing == None:\n",
    "        priceRange.append([])\n",
    "    elif len(pricing) == 1:\n",
    "        priceRange.append(pricing[0].text)\n",
    "    elif len(pricing) > 1:\n",
    "        priceRange.append(pricing[1].text)\n",
    "\n",
    "    nP = soup2.find(\"span\", class_=\"display--inline__373c0__1DbOG margin-l2__373c0__wvUpT border-color--default__373c0__2oFDT\")\n",
    "    if nP == None:\n",
    "        numberOfPhotos.append([])\n",
    "    else:\n",
    "        numberOfPhotos.append(nP.find(\"span\", class_=\"css-ardur\").text.split()[1])\n",
    "\n",
    "    loc = soup2.find_all(\"p\", class_=\"css-8yg8ez\")\n",
    "    if loc == None:\n",
    "        location.append([])\n",
    "    elif len(loc) < 3:\n",
    "        location.append([])\n",
    "    else:\n",
    "        location.append(loc[2].text)\n",
    "\n",
    "    str = soup2.find_all(\"span\", class_=\"raw__373c0__3rcx7\")\n",
    "    if str == None:\n",
    "        street.append([])\n",
    "    elif len(str) < 2:\n",
    "        street.append([])\n",
    "    else:\n",
    "        street.append(str[1].text)\n",
    "\n",
    "    cl = soup2.find(\"a\", class_=\"css-166la90\")\n",
    "    if cl == None:\n",
    "        classification.append([])\n",
    "    else:\n",
    "        classification.append(cl.text)\n",
    "\n",
    "    amen = soup2.find_all(\"span\", class_=\"css-1h1j0y3\")\n",
    "    if amen == None:\n",
    "        amenities.append([])\n",
    "    else:\n",
    "        for i in range(len(amen)):\n",
    "            amenity.append(amen[i].text)\n",
    "        amenities.append(amenity)\n",
    "        amenity = []\n",
    "        \n",
    "# page2 = requests.get(\"https://www.yelp.co.uk/biz/artotel-amsterdam-amsterdam-2?osq=Hotels\")\n",
    "\n",
    "# soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "\n",
    "# # rate = soup2.find(\"span\",class_= \"display--inline__373c0__2SfH_ border-color--default__373c0__30oMI\")\n",
    "# # # if rate == None:\n",
    "# # #     ratings.append([])\n",
    "# # # elif ratings == 1:\n",
    "# # # #     rate = str(rate)\n",
    "# # #     ratings.append(re.findall('aria-label=\"(\\S+)', str(rate)))\n",
    "# # # else:\n",
    "# # # #     rate = str(rate)\n",
    "# # #     ratings.append(re.findall('aria-label=[0-9][.[0-9]]?', rate)[0])\n",
    "# # rate = str(rate)\n",
    "# # ratings.append(re.findall('aria-label=\"(\\S+)',rate)[0])\n",
    "\n",
    "# # # bN= soup2.find(\"h1\", class_=\"css-11q1g5y\")\n",
    "# # # type(bN)\n",
    "# # ratings\n",
    "# # # ratings.append(re.findall('aria-label=\"(\\S+)', str(rate)))\n",
    "# # # ratings\n",
    "\n",
    "# bN= soup2.find(\"h1\", class_=\"css-11q1g5y\")\n",
    "# if bN == None:\n",
    "#     hotelNames.append([])\n",
    "# else:\n",
    "#     hotelNames.append(bN.text)\n",
    "    \n",
    "# print(hotelNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee799170",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotelNames = []\n",
    "ratings = []\n",
    "numberOfReviews= []\n",
    "priceRange = []\n",
    "numberOfPhotos = []\n",
    "location = []\n",
    "street = []\n",
    "classification = []\n",
    "amenities = []\n",
    "amenity = []\n",
    "\n",
    "for link in pageLinks[50:]:\n",
    "    \n",
    "    \n",
    "    page2 = requests.get(link)\n",
    "    \n",
    "    \n",
    "    soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "    \n",
    "    bN= soup2.find(\"h1\", class_=\"css-11q1g5y\")\n",
    "    if bN == None:\n",
    "        hotelNames.append([])\n",
    "    else:\n",
    "        hotelNames.append(bN.text)\n",
    "\n",
    "#     rate = soup2.find(\"span\", class_=\"display--inline__373c0__2SfH_ border-color--default__373c0__30oMI\")\n",
    "#     if rate == None:\n",
    "#         ratings.append([])\n",
    "#     elif ratings == 1:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate))\n",
    "#     else:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate)[0])\n",
    "\n",
    "    nR = soup2.find(\"span\", class_=\"css-bq71j2\")\n",
    "    if nR == None:\n",
    "        numberOfReviews.append([])\n",
    "    else:\n",
    "        numberOfReviews.append(nR.text.split()[0])\n",
    "\n",
    "    pricing = soup2.find_all(\"span\", class_=\"css-1xxismk\")\n",
    "    if len(pricing) == 0 or pricing == None:\n",
    "        priceRange.append([])\n",
    "    elif len(pricing) == 1:\n",
    "        priceRange.append(pricing[0].text)\n",
    "    elif len(pricing) > 1:\n",
    "        priceRange.append(pricing[1].text)\n",
    "\n",
    "    nP = soup2.find(\"span\", class_=\"display--inline__373c0__1DbOG margin-l2__373c0__wvUpT border-color--default__373c0__2oFDT\")\n",
    "    if nP == None:\n",
    "        numberOfPhotos.append([])\n",
    "    else:\n",
    "        numberOfPhotos.append(nP.find(\"span\", class_=\"css-ardur\").text.split()[1])\n",
    "\n",
    "    loc = soup2.find_all(\"p\", class_=\"css-8yg8ez\")\n",
    "    if loc == None:\n",
    "        location.append([])\n",
    "    elif len(loc) < 3:\n",
    "        location.append([])\n",
    "    else:\n",
    "        location.append(loc[2].text)\n",
    "\n",
    "    str = soup2.find_all(\"span\", class_=\"raw__373c0__3rcx7\")\n",
    "    if str == None:\n",
    "        street.append([])\n",
    "    elif len(str) < 2:\n",
    "        street.append([])\n",
    "    else:\n",
    "        street.append(str[1].text)\n",
    "\n",
    "    cl = soup2.find(\"a\", class_=\"css-166la90\")\n",
    "    if cl == None:\n",
    "        classification.append([])\n",
    "    else:\n",
    "        classification.append(cl.text)\n",
    "\n",
    "    amen = soup2.find_all(\"span\", class_=\"css-1h1j0y3\")\n",
    "    if amen == None:\n",
    "        amenities.append([])\n",
    "    else:\n",
    "        for i in range(len(amen)):\n",
    "            amenity.append(amen[i].text)\n",
    "        amenities.append(amenity)\n",
    "        amenity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a88ad600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in pageLinks[190:]:\n",
    "    \n",
    "    \n",
    "    page2 = requests.get(link)\n",
    "    \n",
    "    \n",
    "    soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "    \n",
    "    bN= soup2.find(\"h1\", class_=\"css-11q1g5y\")\n",
    "    if bN == None:\n",
    "        hotelNames.append([])\n",
    "    else:\n",
    "        hotelNames.append(bN.text)\n",
    "\n",
    "#     rate = soup2.find(\"span\", class_=\"display--inline__373c0__2SfH_ border-color--default__373c0__30oMI\")\n",
    "#     if rate == None:\n",
    "#         ratings.append([])\n",
    "#     elif ratings == 1:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate))\n",
    "#     else:\n",
    "#         rate = str(rate)\n",
    "#         ratings.append(re.findall('aria-label=\"(\\S+)', rate)[0])\n",
    "\n",
    "    nR = soup2.find(\"span\", class_=\"css-bq71j2\")\n",
    "    if nR == None:\n",
    "        numberOfReviews.append([])\n",
    "    else:\n",
    "        numberOfReviews.append(nR.text.split()[0])\n",
    "\n",
    "    pricing = soup2.find_all(\"span\", class_=\"css-1xxismk\")\n",
    "    if len(pricing) == 0 or pricing == None:\n",
    "        priceRange.append([])\n",
    "    elif len(pricing) == 1:\n",
    "        priceRange.append(pricing[0].text)\n",
    "    elif len(pricing) > 1:\n",
    "        priceRange.append(pricing[1].text)\n",
    "\n",
    "    nP = soup2.find(\"span\", class_=\"display--inline__373c0__1DbOG margin-l2__373c0__wvUpT border-color--default__373c0__2oFDT\")\n",
    "    if nP == None:\n",
    "        numberOfPhotos.append([])\n",
    "    else:\n",
    "        numberOfPhotos.append(nP.find(\"span\", class_=\"css-ardur\").text.split()[1])\n",
    "\n",
    "    loc = soup2.find_all(\"p\", class_=\"css-8yg8ez\")\n",
    "    if loc == None:\n",
    "        location.append([])\n",
    "    elif len(loc) < 3:\n",
    "        location.append([])\n",
    "    else:\n",
    "        location.append(loc[2].text)\n",
    "\n",
    "    str = soup2.find_all(\"span\", class_=\"raw__373c0__3rcx7\")\n",
    "    if str == None:\n",
    "        street.append([])\n",
    "    elif len(str) < 2:\n",
    "        street.append([])\n",
    "    else:\n",
    "        street.append(str[1].text)\n",
    "\n",
    "    cl = soup2.find(\"a\", class_=\"css-166la90\")\n",
    "    if cl == None:\n",
    "        classification.append([])\n",
    "    else:\n",
    "        classification.append(cl.text)\n",
    "\n",
    "    amen = soup2.find_all(\"span\", class_=\"css-1h1j0y3\")\n",
    "    if amen == None:\n",
    "        amenities.append([])\n",
    "    else:\n",
    "        for i in range(len(amen)):\n",
    "            amenity.append(amen[i].text)\n",
    "        amenities.append(amenity)\n",
    "        amenity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58c43f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57',\n",
       " '4',\n",
       " '10',\n",
       " '30',\n",
       " '4',\n",
       " '25',\n",
       " '18',\n",
       " '23',\n",
       " '4',\n",
       " '33',\n",
       " '7',\n",
       " '1',\n",
       " '16',\n",
       " '18',\n",
       " '23',\n",
       " '13',\n",
       " '22',\n",
       " '22',\n",
       " '15',\n",
       " 'Hotels',\n",
       " '2',\n",
       " '8',\n",
       " '14',\n",
       " 'Hotels',\n",
       " '25',\n",
       " '1',\n",
       " '3',\n",
       " '14',\n",
       " '15',\n",
       " 'Hotels',\n",
       " '48',\n",
       " '10',\n",
       " '2',\n",
       " '6',\n",
       " '11',\n",
       " '28',\n",
       " '11',\n",
       " '1',\n",
       " '6',\n",
       " '32',\n",
       " '4',\n",
       " '6',\n",
       " '2',\n",
       " '17',\n",
       " '15',\n",
       " '13',\n",
       " '2',\n",
       " '6',\n",
       " '29',\n",
       " '11',\n",
       " '15',\n",
       " '2',\n",
       " '21',\n",
       " '7',\n",
       " '21',\n",
       " '1',\n",
       " '15',\n",
       " '29',\n",
       " '4',\n",
       " '3',\n",
       " '3',\n",
       " '7',\n",
       " '9',\n",
       " '12',\n",
       " '4',\n",
       " '10',\n",
       " '6',\n",
       " '11',\n",
       " '31',\n",
       " '8',\n",
       " '9',\n",
       " '1',\n",
       " [],\n",
       " '1',\n",
       " '18',\n",
       " '7',\n",
       " '29',\n",
       " '13',\n",
       " '5',\n",
       " '1',\n",
       " '10',\n",
       " '14',\n",
       " '51',\n",
       " '15',\n",
       " '1',\n",
       " '17',\n",
       " '13',\n",
       " '3',\n",
       " [],\n",
       " '3',\n",
       " '11',\n",
       " '10',\n",
       " '14',\n",
       " '3',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " 'Hotels',\n",
       " '25',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '30',\n",
       " '10',\n",
       " '2',\n",
       " '1',\n",
       " '15',\n",
       " '2',\n",
       " '14',\n",
       " '13',\n",
       " '6',\n",
       " '4',\n",
       " '1',\n",
       " '11',\n",
       " '2',\n",
       " '14',\n",
       " 'Hotels',\n",
       " '2',\n",
       " '1',\n",
       " '14',\n",
       " '1',\n",
       " '3',\n",
       " '19',\n",
       " '1',\n",
       " '2',\n",
       " 'Hotels',\n",
       " '3',\n",
       " 'Hotels',\n",
       " [],\n",
       " '32',\n",
       " '6',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '18',\n",
       " '1',\n",
       " '1',\n",
       " '34',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '21',\n",
       " '18',\n",
       " '3',\n",
       " '4',\n",
       " 'Hotels',\n",
       " '9',\n",
       " '4',\n",
       " '6',\n",
       " '2',\n",
       " '15',\n",
       " '7',\n",
       " '12',\n",
       " '2',\n",
       " '4',\n",
       " [],\n",
       " '3',\n",
       " 'Hotels',\n",
       " '3',\n",
       " 'Hotels',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " 'Hotels',\n",
       " 'Hotel',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '3',\n",
       " '23',\n",
       " '14',\n",
       " '7',\n",
       " '11',\n",
       " '41',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '4',\n",
       " '13',\n",
       " '2',\n",
       " 'Hotels',\n",
       " '4',\n",
       " '9',\n",
       " '2',\n",
       " '7',\n",
       " '2',\n",
       " '3',\n",
       " '7',\n",
       " '9',\n",
       " '11',\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfReviews"
   ]
  },
  {
   "cell_type": "raw",
   "id": "670a8c29",
   "metadata": {},
   "source": [
    "dfRatings = pd.read_csv('bar Ratings.csv')\n",
    "\n",
    "dfRatings.columns = [\"S/N\", \"Ratings\"]\n",
    "\n",
    "ratings = dfRatings[\"Ratings\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a45a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Names':hotelNames, 'Rating':ratings, 'Number_of_review':numberOfReviews, 'Street':street, 'Locations':location, 'price_range':priceRange, 'Number_of_photos':numberOfPhotos, 'kind':classification, 'Amenities':amenities}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('Collated Hotel Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3333e2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '[]',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '4',\n",
       " '3.5',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '3',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '5',\n",
       " '3.5',\n",
       " '4.5',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4.5',\n",
       " '[]',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '[]',\n",
       " '4.5',\n",
       " '5',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '4',\n",
       " '[]',\n",
       " '3.5',\n",
       " '4',\n",
       " '5',\n",
       " '4.5',\n",
       " '4',\n",
       " '3',\n",
       " '3',\n",
       " '5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '3',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '3.5',\n",
       " '2.5',\n",
       " '3',\n",
       " '4.5',\n",
       " '4',\n",
       " '4',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '5',\n",
       " '3.5',\n",
       " '4',\n",
       " '3.5',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '2.5',\n",
       " '3',\n",
       " '4',\n",
       " '3.5',\n",
       " '5',\n",
       " '4',\n",
       " '4.5',\n",
       " '3',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '3.5',\n",
       " '4',\n",
       " '3.5',\n",
       " '[]',\n",
       " '5',\n",
       " '4.5',\n",
       " '3.5',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '4',\n",
       " '4.5',\n",
       " '4.5',\n",
       " '[]',\n",
       " '4',\n",
       " '3.5',\n",
       " '5',\n",
       " '3.5',\n",
       " '3',\n",
       " '3',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3',\n",
       " '5',\n",
       " '2',\n",
       " '3',\n",
       " '4.5',\n",
       " '3',\n",
       " '[]',\n",
       " '4',\n",
       " '4',\n",
       " '[]',\n",
       " '3',\n",
       " '4.5',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '4',\n",
       " '4.5',\n",
       " '[]',\n",
       " '[]',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '4.5',\n",
       " '4',\n",
       " '4.5',\n",
       " '4',\n",
       " '5',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '3',\n",
       " '4',\n",
       " '2.5',\n",
       " '2.5',\n",
       " '[]',\n",
       " '3.5',\n",
       " '4',\n",
       " '2.5',\n",
       " '2.5',\n",
       " '3',\n",
       " '4',\n",
       " '3.5',\n",
       " '4',\n",
       " '2.5',\n",
       " '4.5',\n",
       " '2.5',\n",
       " '[]',\n",
       " '4',\n",
       " '[]',\n",
       " '4.5',\n",
       " '3',\n",
       " '2',\n",
       " '4',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
